import json
import re
import os
import requests
from dotenv import load_dotenv
from google.generativeai import configure, GenerativeModel
from typing import List, Dict

# Load environment variables
load_dotenv()

# Get Gemini API key
api_key = os.getenv("GEMINI_API_KEY") or ""
if not api_key:
    print("‚ö†Ô∏è Warning: GEMINI_API_KEY not found. Running in fallback mode.\n")

# Configure Gemini
SYSTEM_INSTRUCTION = (
    "You are a precise URL generator for extracting company interview questions. "
    "Focus ONLY on these 3 sources:\n"
    "- GeeksforGeeks: https://www.geeksforgeeks.org/dsa/{company}-sde-sheet-interview-questions-and-answers/\n"
    "- InterviewBit: https://www.interviewbit.com/{company}-interview-questions/\n"
    "- PrepInsta: https://prepinsta.com/{company}/\n"
    "Make sure the URLs are valid, public, and directly point to interview question pages."
)

configure(api_key=api_key)
gemini_model = GenerativeModel("gemini-2.5-flash", system_instruction=SYSTEM_INSTRUCTION)


def normalize_input(text: str) -> str:
    """Normalize company name or role."""
    return re.sub(r'\s+', '-', text.strip().lower())


def is_url_valid(url: str, timeout: int = 8) -> bool:
    """Validate URL accessibility."""
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
    try:
        r = requests.get(url, timeout=timeout, allow_redirects=True, headers=headers)
        return 200 <= r.status_code < 400
    except Exception:
        return False


def generate_queries(company: str, role: str) -> List[Dict]:
    company_norm = normalize_input(company)
    role_norm = normalize_input(role)

    prompt = f"""
    Generate JSON output for interview question pages of company '{company}' for role '{role}'.
    Use ONLY these sites and URL formats:

    - GeeksforGeeks: "https://www.geeksforgeeks.org/dsa/{company_norm}-sde-sheet-interview-questions-and-answers/"
    - InterviewBit: "https://www.interviewbit.com/{company_norm}-interview-questions/"
    - PrepInsta: "https://prepinsta.com/{company_norm}/"

    Output STRICT JSON array:
    [
      {{"site": "GeeksforGeeks", "search_query": "{company} {role} interview questions", "initial_url_guess": "<url>"}},
      {{"site": "InterviewBit", "search_query": "{company} {role} interview questions", "initial_url_guess": "<url>"}},
      {{"site": "PrepInsta", "search_query": "{company} {role} interview questions", "initial_url_guess": "<url>"}}
    ]
    """

    try:
        response = gemini_model.generate_content(prompt)
        text = response.text.strip()
        if text.startswith("```json"):
            text = text[7:-3].strip()
        data = json.loads(text)
    except Exception as e:
        print(f"‚ö†Ô∏è Gemini API error: {e}. Using fallback URLs.")
        data = [
            {
                "site": "GeeksforGeeks",
                "search_query": f"{company} {role} interview questions",
                "initial_url_guess": f"https://www.geeksforgeeks.org/dsa/{company_norm}-sde-sheet-interview-questions-and-answers/"
            },
            {
                "site": "InterviewBit",
                "search_query": f"{company} {role} interview questions",
                "initial_url_guess": f"https://www.interviewbit.com/{company_norm}-interview-questions/"
            },
            {
                "site": "PrepInsta",
                "search_query": f"{company} {role} interview questions",
                "initial_url_guess": f"https://prepinsta.com/{company_norm}/"
            }
        ]

    # Validate URLs
    for q in data:
        url = q.get("initial_url_guess", "")
        q["valid"] = is_url_valid(url)
        q["url"] = url

    return data


def main():
    company = input("Enter company name (e.g., Amazon): ").strip()
    role = input("Enter role (e.g., SDE): ").strip()

    print(f"\nüîç Generating queries for {company} {role} ...")
    queries = generate_queries(company, role)

    output_file = f"{normalize_input(company)}_{normalize_input(role)}_queries.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(queries, f, indent=2)

    print(f"\n‚úÖ Queries saved to {output_file}:\n")
    for q in queries:
        print(f"- {q['site']}: {q['url']} ({'‚úÖ Valid' if q['valid'] else '‚ùå Invalid'})")


if __name__ == "__main__":
    main()
